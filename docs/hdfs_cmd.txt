> HDFS_CMD    

  THIS IS A MODIFIED VERSION OF THE [command] MODULE which lookup `creates' and `removes' files in HDFS instead of local file.
  The [hdfs_cmd] module takes a `cmd' option holding all the command line to be executed The given command will be executed on
  all selected nodes. By default it will not be processed through the shell, so variables like `$HOME' and operations like `"<"',
  `">"', `"|"', and `"&"' will not work (Set uses_shell=true to activate theses features).

Supported by: community

Status: preview

Options (= is mandatory):

- auth
        Define account to impersonate to perform required operation. Technically, this value will be inserted between the path
        and the `op=XXXXX' value of the built URL. Refer to `https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-
        hdfs/WebHDFS.html#Authentication' for more information.
        [Default: user.name=hdfs]
- chdir
        cd into this directory before running the command
        [Default: None]
= cmd
        the command to execute.
        [Default: None]
- executable
        change the shell used to execute the command. Should be an absolute path to the executable.
        [Default: None]
- hadoop_conf_dir
        Where to find Haddop configuration file, specially hdfs-site.xml, in order to lookup WebHDFS endpoint (`dfs.namenode
        .http-address') Used only if webhdfs_endpoint is not defined
        [Default: /etc/hadoop/conf]
- hdfs_creates
        an absolute HDFS path, when it already exists, this step will *not* be run.
        [Default: None]
- hdfs_removes
        an absolute HDFS path, when it does not exist, this step will *not* be run.
        [Default: None]
- uses_shell
        Activate shell mode. Same as `shell' module against `command' module.
        [Default: (null)]
- webhdfs_endpoint
        Provide WebHDFS REST API entry point. Typically `<namenodeHost>:50070'. If not defined, will be looked up in local hdfs-
        site.xml
        [Default: None]
Notes:
  * If you want to run a command through the shell (say you are using `<', `>', `|', etc), you actually need to set
        uses_shell=true. The [command] module is much more secure as it's not affected by the user's environment.
  *  `creates', `removes', and `chdir' can be specified after the command. For instance, if you only want to run a command
        if a certain file does not exist, use this.
  * As HDFS is a distributed file system shared by all nodes of a cluster, this module must be launched on one node only.
        Note there is no protection against race condition (Same operation performed simultaneously from several nodes).
  * All HDFS operations are performed using WebHDFS REST API.
EXAMPLES:

# How to copy a file from the file system of the targeted host to HDFS
- hdfs_cmd: cmd="sudo -u joe hdfs dfs -put /etc/passwd /user/joe/passwd1" hdfs_creates=/user/joe/passwd1

# Same, using different syntax
- hdfs_cmd: cmd="sudo -u joe hdfs dfs -put /etc/passwd /user/joe/passwd2"
  args:
    hdfs_creates: /user/joe/passwd2
    
# Same, using different syntax
- name: "Copy passwd3 to hdfs"
  hdfs_cmd: 
    cmd: sudo -u joe hdfs dfs -put ./passwd /user/joe/passwd3
    hdfs_creates: /user/joe/passwd3
    chdir: /etc

# Copy the file and adjust permissions using hdfs_file
- hdfs_cmd: cmd="sudo -u hdfs hdfs dfs -put /etc/passwd /user/joe/passwd4" hdfs_creates=/user/joe/passwd4
- hdfs_file: hdfs_path=/user/joe/passwd4 owner=joe group=users mode=0770
      


MAINTAINERS: Ansible Core Team, Michael DeHaan, Serge ALEXANDRE
